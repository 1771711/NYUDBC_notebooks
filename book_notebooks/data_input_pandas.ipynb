{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data via `Pandas`\n",
    "\n",
    "\n",
    "\n",
    "This is a key step. It's actually quite easy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have our packages, the `os` one is new. It allows us to get information about our computer, and most importantly information about the path, current working directory etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Grabbing stuff from the web. \n",
    "\n",
    "First, this is the ideal way to go. Why? The key issue is that by just pointing to where it is stored anyone can go there and replicate, exlpore your results. In other words, everyone is working off of the same dataset or \"gold plates\" as I like to call it. In contrast, you may have data on your local computer, change it, save it. Then when if you try and do the same calculations on the data, you won't replicate your results. Why? You changed the data!\n",
    "\n",
    "This is actually a big issue for companies: [see here](https://www.wsj.com/articles/stop-using-excel-finance-chiefs-tell-staffs-1511346601)\n",
    "\n",
    "Great! How do I do it...here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url1 = \"https://raw.githubusercontent.com/NYUDataBootcamp\"\n",
    "\n",
    "url2 = \"/Materials/master/Data/test.csv\"\n",
    "\n",
    "url  = url1 + url2        # location of the file on the www\n",
    "\n",
    "df = pd.read_csv(url)     # read file and assign it to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So simple and clean. Very nice. Let's explore some more: Explore the help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_only2 = pd.read_csv(url, nrows = 2)\n",
    "\n",
    "df_only2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then this is cool too, set certain values to be read in as NaN (not a number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_notone = pd.read_csv(url, na_values = 1)\n",
    "\n",
    "df_notone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets read in a different type of file an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url3 = \"/Materials/master/Data/test.xls\"\n",
    "url = url1 + url3\n",
    "\n",
    "df_excel = pd.read_excel(url, na_values = 1) # Simmilar funcitonality!\n",
    "\n",
    "df_excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Exercise.** Modify the code above, so it reads in the file `test0.csv` What happens?\n",
    "\n",
    "\n",
    "- **Exercise.** Delete the 0 in test0 and rerun the code. What happens if you add the argument index_col=0 to the read_csv statement? How does df change?\n",
    "\n",
    "\n",
    "- **Exercise.** In the read_excel code, change the file extension at the end of url2 from .xls to .xlsx. What does the new code produce?\n",
    "\n",
    "\n",
    "- **Exercise.** Adapt the read_csv code to treat the numbers 1 and 6 as missing. Hint: See the example a page or so back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Reading in data from your computer...\n",
    "\n",
    "This is important to know how to do as well. As you can imagine its useful all the time. It can be also helpful in the case that (i) you don't have internet access and (ii) for big data sets reading stuff on the web all the time might be slower that just reading in a local copy. So as you work on your projects, working off a local copy to experiment and play is not a bad idea.\n",
    "\n",
    "First, lets write the data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"df.csv\")\n",
    "\n",
    "df.to_excel(\"df.xlsx\")\n",
    "\n",
    "df.to_excel(\"df.xls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next question? **WHERE IS THE DATA**\n",
    "\n",
    "With those commands it wrote this to your working directory. What does that mean, the folder that you are working in. Where is that...\n",
    "- First, in jupyter just got to your browser window from which you opened a new notebook. It should be open in the folder that you started from (which is your working directory). Look there. See the files.\n",
    "\n",
    "\n",
    "- Second, in python, we can find this out as well but using the os command.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_path = os.getcwd()\n",
    "my_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of things about this: This should seem kind of familiar. In a PC, there is a difference it will show ``\\\\`` double backslashes...not the typical single backslash. **ON A MAC IT WILL BE YOUR STANDARD FOWARD SLASH**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use the path to write the data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(my_path + \"\\\\\"+\"df1.csv\")\n",
    "\n",
    "df.to_excel(my_path + \"\\\\\"+\"df1.xlsx\")\n",
    "\n",
    "df.to_excel(my_path + \"\\\\\"+\"df1.xls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read it in..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = pd.read_excel(\"df1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets read it in with the complete path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = pd.read_excel(my_path + \"\\\\\" + \"df1.xlsx\")\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** \n",
    "- Create a folder from the \"home interface of jupyer\"\n",
    "- write the data frame to that folder\n",
    "- read in the data from that folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Input Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_new = pd.read_excel(\"https://github.com/nyusterndatabootcamp/data_resources/blob/master/Data_Input_Notebook.xlsx\")\n",
    "\n",
    "In pandas, we have several options when read data from csv or excels. Let's try to learn some of them.\n",
    "\n",
    "First please download the data from this [link](\"https://github.com/nyusterndatabootcamp/data_resources/blob/master/Data_Input_Notebook.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Needs discussion.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Grabbing specific sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first read the first sheet into our dataframe\n",
    "df = pd.read_excel(\"/Users/tinghao/Desktop/Data_Input_Notebook.xlsx\",sheet_name='People')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the data reading results are not satisfactory. Because of the header and footers, the original column names/headings are wrongly input as the row values, while columns are left undefined. Too bad, let's fix them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Skipping footer or headers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Skipping the footers\n",
    "# note, we need to skip two rows to entirely skip the footer as we see from the table above\n",
    "df = pd.read_excel(\"/Users/tinghao/Desktop/Data_Input_Notebook.xlsx\",\n",
    "                   sheet_name='People',\n",
    "                   skipfooter=2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Skipping the headers\n",
    "# note, we need to skip two rows to entirely skip the footer as we see from the table above\n",
    "df = pd.read_excel(\"/Users/tinghao/Desktop/Data_Input_Notebook.xlsx\",\n",
    "                   sheet_name='People',\n",
    "                   skipfooter=2,\n",
    "                  skiprows=2)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, finally we get the dataset we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3: Grabbing specific columns\n",
    "\n",
    "Sometimes, especaily for a really wide and long datasets, it could be very slow/impossible to import the entire dataset at once and we might be only interested in one or some columns. We could specify this by input options as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Think about we are only interested in \"Name\" column. Remeber the brackets.\n",
    "\n",
    "df = pd.read_excel(\"/Users/tinghao/Desktop/Data_Input_Notebook.xlsx\",\n",
    "                   sheet_name='People',\n",
    "                   skipfooter=2,\n",
    "                  skiprows=2,\n",
    "                  usecols=[\"Name\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tinghao's' comment:\n",
    "in general, I'd prefer the following way so that we do not have to remember “usecols” parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/Users/tinghao/Desktop/Data_Input_Notebook.xlsx\",\n",
    "                   sheet_name='People',\n",
    "                   skipfooter=2,\n",
    "                  skiprows=2)[\"Name\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 4: Headings \n",
    "Sometimes, the origianl data may multi level column names for two level indexing column like the one we saw here. We could use `skiprows` parameter as we learned and input all the columns like the usual ones. However, we can also take advantage of the multi-level indexing. This can be incredibly useful if you have hundreds of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/Users/tinghao/Desktop/Data_Input_Notebook.xlsx\",\n",
    "                   sheet_name='People',\n",
    "                   skipfooter=2,\n",
    "                   skiprows=1,\n",
    "                  header=[0,1])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the information regarding each person via..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Person']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 5: Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_excel(\"/Users/tinghao/Desktop/Data_Input_Notebook.xlsx\",\n",
    "                   sheetname='Children',\n",
    "                   )\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some two records with **\".\"** or **\"-\"**, it might indicate different ways of encoding missing values when data collected. However, we might have difficulties when we perform operations on the Age column, e.g., such as sum or mean. \n",
    "\n",
    "We can first transfer them into a python standard format for representing missing values by specifying the `na_values = [\".\",\"-\"]` in the `read_excel` methods in pandas. Then operations will be much easier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/Users/tinghao/Desktop/Data_Input_Notebook.xlsx\",\n",
    "                   sheetname='Children',\n",
    "                   na_values = [\".\",\"-\"],\n",
    "                   )\n",
    "print(df)\n",
    "print(df.sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 6: Character Encoding Error for \"csv\" File\n",
    "\n",
    "This error happens if and only if the file contains characters which are not supported by the default encoding (known as `utf-8`) this can cause `read_csv` methods in `pandas` to generate errors. If interested, you can find the technical details [here](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/) \n",
    "\n",
    "In addition, detecting the encoding of a file can be tricky and need to work with other packages in python. More discussion can be found [here.](https://stackoverflow.com/questions/436220/determine-the-encoding-of-text-in-python)\n",
    "\n",
    "Normally, you can then try the following encodings, in this order:\n",
    "\n",
    "* iso-8859-1 (also known as latin-1 and it is the encoding of all census data and much other data produced by government entities.)\n",
    "* utf-16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/tinghao/Desktop/utf_8_encode.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/tinghao/Desktop/utf_16_encode.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/tinghao/Desktop/utf_16_encode.csv\",encoding='utf-16')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see from this example, it seems that the two columns have not been **separated** and connected via **\"\\t\"**. How do we separate them and parse the data into desirable formt? We will find next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 7: Sperators\n",
    "\n",
    "In `pandas`, we solve the above problem by setting different values of `sep` parameter in `read_csv` method.\n",
    "\n",
    "For example...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/tinghao/Desktop/utf_16_encode.csv\",encoding='utf-16',sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should we do if have multiple separators in one dataset? **Needs discussion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Let's Practice\n",
    "\n",
    "### Example #1: Penn World Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"http://www.rug.nl/ggdc/docs/pwt81.xlsx\"                   # Here is the correct link\n",
    "   \n",
    "pwt = pd.read_excel(url, sheetname= \"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excercise\n",
    "- What is its shape?\n",
    "- What are the column names?\n",
    "- Download the worksheet as an excel file (just past the link in the browser) What does it look like?\n",
    "- Exercise. Change the input in the last line of code to sheet_name=2. Why does this work?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "country_summary = pwt.country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example #2: Pisa Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://dx.doi.org/10.1787/888932937035'\n",
    "\n",
    "pisa = pd.read_excel(url,\n",
    "                     skiprows=18,             # skip the first 18 rows\n",
    "                     skipfooter=7,            # skip the last 7\n",
    "                     parse_cols=[0,1,9,13],   # select columns of interest\n",
    "                     index_col=0,             # set the index as the first column\n",
    "                     header=[0,1]             # set the variable names\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pisa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pisa = pisa.dropna() ## Drop missing values\n",
    "\n",
    "pisa.columns = ['Math', 'Reading', 'Science'] # Rename the columns, note that this is setup orginally as a multiindex \n",
    "\n",
    "pisa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pisa.Math.describe()\n",
    "\n",
    "pisa.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pisa.loc[\"United States\"] / pisa.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries = [\"United States\", \"Singapore\", \"Argentina\", \"Sweden\"]\n",
    "\n",
    "# pisa[\"Math\"][countries].plot(kind = 'barh') My first attack on this...\n",
    "\n",
    "pisa[\"Math\"][countries].sort_values().plot(kind = 'barh', color = \"blue\", alpha = 0.5) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example #3: Movie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url  = 'http://pages.stern.nyu.edu/~dbackus/Data/cast.csv'\n",
    "cast = pd.read_csv(url)\n",
    "\n",
    "# some stuff on encoding\n",
    "# http://pandaproject.net/docs/determining-the-encoding-of-a-csv-file.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cast.head()\n",
    "\n",
    "cast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cast.title.value_counts().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cast.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cast.set_index(\"name\").loc[\"George Clooney\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cast.set_index(\"name\").loc[\"George Clooney\"].year.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cast.set_index(\"title\").loc[\"Star Wars\"].sort_values(\"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
